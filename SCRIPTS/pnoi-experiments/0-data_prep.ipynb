{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATASET FOR PNOI EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "mkdir = lambda p: 0 if os.path.exists(p) else (os.mkdir(p), 1)[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHS to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS = \"reports\"; mkdir(REPORTS) # Path to the reports folder\n",
    "\n",
    "PNOI_CORPUS_CSV_NAME = \"pnoicorpus_muster.csv\" # Name of the csv file\n",
    "\n",
    "PNOI_CORPUS_CSV_PATH = f\"{REPORTS}/{PNOI_CORPUS_CSV_NAME}\" # Path to the master csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>app_code</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>subjectName</th>\n",
       "      <th>subjectGender</th>\n",
       "      <th>subjectAge</th>\n",
       "      <th>subjectType</th>\n",
       "      <th>subjectHeight</th>\n",
       "      <th>subjectWeight</th>\n",
       "      <th>META</th>\n",
       "      <th>...</th>\n",
       "      <th>LBA_after_RU</th>\n",
       "      <th>anot--LBA_after_RU</th>\n",
       "      <th>LBA_after_LL</th>\n",
       "      <th>anot--LBA_after_LL</th>\n",
       "      <th>LBA_after_RL</th>\n",
       "      <th>anot--LBA_after_RL</th>\n",
       "      <th>PFT_before</th>\n",
       "      <th>anot--PFT_before</th>\n",
       "      <th>PFT_after</th>\n",
       "      <th>anot--PFT_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pnoistor_feb2023</td>\n",
       "      <td>shreyamgupta_78aa423a</td>\n",
       "      <td>Shreyam Gupta</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>Control</td>\n",
       "      <td>158</td>\n",
       "      <td>70</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pnoistor_dec01</td>\n",
       "      <td>sannashoukat_5213fe84</td>\n",
       "      <td>Sanna Shoukat</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Control</td>\n",
       "      <td>166</td>\n",
       "      <td>55</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pnoistor_feb2023</td>\n",
       "      <td>sananaushad_80e84b51</td>\n",
       "      <td>Sana Naushad</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Control</td>\n",
       "      <td>158</td>\n",
       "      <td>60</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pnoistor_dec01</td>\n",
       "      <td>saikeerthanaarun_3364bc1a</td>\n",
       "      <td>Sai Keerthana Arun</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Control</td>\n",
       "      <td>172</td>\n",
       "      <td>58</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/saikeerthanaarun_...</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>pnoistor_dec01</td>\n",
       "      <td>kumarchowdam_53f32e31</td>\n",
       "      <td>Kumar Chowdam</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>Control</td>\n",
       "      <td>162</td>\n",
       "      <td>60</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...</td>\n",
       "      <td>DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          app_code                     sub_id         subjectName  \\\n",
       "0      0  pnoistor_feb2023      shreyamgupta_78aa423a       Shreyam Gupta   \n",
       "1      2    pnoistor_dec01      sannashoukat_5213fe84       Sanna Shoukat   \n",
       "2      3  pnoistor_feb2023       sananaushad_80e84b51        Sana Naushad   \n",
       "3      4    pnoistor_dec01  saikeerthanaarun_3364bc1a  Sai Keerthana Arun   \n",
       "4      6    pnoistor_dec01      kumarchowdam_53f32e31       Kumar Chowdam   \n",
       "\n",
       "  subjectGender  subjectAge subjectType  subjectHeight  subjectWeight  \\\n",
       "0        Female          19     Control            158             70   \n",
       "1        Female          21     Control            166             55   \n",
       "2        Female          21     Control            158             60   \n",
       "3        Female          22     Control            172             58   \n",
       "4          Male          21     Control            162             60   \n",
       "\n",
       "                                                META  ... LBA_after_RU  \\\n",
       "0  DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...  ...            -   \n",
       "1  DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...  ...            -   \n",
       "2  DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...  ...            -   \n",
       "3  DATA_PNOISTOR/pnoistor_dec01/saikeerthanaarun_...  ...            -   \n",
       "4  DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...  ...            -   \n",
       "\n",
       "  anot--LBA_after_RU LBA_after_LL anot--LBA_after_LL LBA_after_RL  \\\n",
       "0                  -            -                  -            -   \n",
       "1                  -            -                  -            -   \n",
       "2                  -            -                  -            -   \n",
       "3                  -            -                  -            -   \n",
       "4                  -            -                  -            -   \n",
       "\n",
       "  anot--LBA_after_RL                                         PFT_before  \\\n",
       "0                  -  DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...   \n",
       "1                  -  DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...   \n",
       "2                  -  DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...   \n",
       "3                  -                                                  -   \n",
       "4                  -  DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...   \n",
       "\n",
       "                                    anot--PFT_before PFT_after anot--PFT_after  \n",
       "0  DATA_PNOISTOR/pnoistor_feb2023/shreyamgupta_78...         -               -  \n",
       "1  DATA_PNOISTOR/pnoistor_dec01/sannashoukat_5213...         -               -  \n",
       "2  DATA_PNOISTOR/pnoistor_feb2023/sananaushad_80e...         -               -  \n",
       "3                                                  -         -               -  \n",
       "4  DATA_PNOISTOR/pnoistor_dec01/kumarchowdam_53f3...         -               -  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataFilter:\n",
    "\n",
    "    EMPTY_VAL = '-'\n",
    "    PNOI_MUSTER_DF: pd.DataFrame\n",
    "\n",
    "    FILTER_DATA_CSV_FNAME = \"filtered_dataset.csv\"\n",
    "\n",
    "    PNOI_FILT_DF: pd.DataFrame\n",
    "\n",
    "    def __init__(self, muster_csv_path: str) -> None:\n",
    "        pnoi_corpus_DF = pd.read_csv(muster_csv_path)\n",
    "        pnoi_corpus_DF.columns = pnoi_corpus_DF.columns.str.replace(\"--file_path\", \"\")\n",
    "\n",
    "        self.PNOI_MUSTER_DF: pd.DataFrame = pnoi_corpus_DF\n",
    "\n",
    "        self.PNOI_FILT_DF: pd.DataFrame = self.filter_df()\n",
    "\n",
    "    def filter_df(self):\n",
    "        # BREATH AUDIO (BA) Columns\n",
    "        col_str_match = r\"anot--LBA_before|anot--VBA_before\" # match string\n",
    "        ba_cols = self.PNOI_MUSTER_DF.columns[self.PNOI_MUSTER_DF.columns.str.contains(col_str_match)] # get columns that match string\n",
    "        filts = [self.PNOI_MUSTER_DF[col] != self.EMPTY_VAL for col in ba_cols] # filters for non-empty values\n",
    "        filt = functools.reduce(lambda p, c: p & c, filts) # combine filters\n",
    "\n",
    "        pnoi_corpus_filt_DF = self.PNOI_MUSTER_DF[filt] # apply filter\n",
    "        pnoi_corpus_filt_DF = pnoi_corpus_filt_DF.reset_index(drop=True) # reset index\n",
    "        pnoi_corpus_filt_DF.to_csv(f\"{REPORTS}/{self.FILTER_DATA_CSV_FNAME}\") # save filtered dataframe to csv\n",
    "        print(pnoi_corpus_filt_DF.shape)\n",
    "        \n",
    "        return pnoi_corpus_filt_DF\n",
    "    \n",
    "pnoidata_filter = DataFilter(PNOI_CORPUS_CSV_PATH)\n",
    "\n",
    "pnoidata_filter.PNOI_FILT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStaticInfo:\n",
    "\n",
    "    VER = \"*\"\n",
    "    SEP = \"-\"\n",
    "    META_SEP = \"_\"\n",
    "    EXT_SEP = \".\"\n",
    "    ANOT_LABELS = [\"aa\", \"ee\", \"uu\", \"oo\", \"ii\", \"xx\", \"bb1\", \"bb2\", \"bb3\", \"bb4\"]\n",
    "\n",
    "    fkeys = {\n",
    "        \"APP_CODE\": \"app_code\",\n",
    "        \"SID\":\"sub_id\",\n",
    "        \"FCLASS\": \"file_class\",\n",
    "        \"FID\": \"file_ID\",\n",
    "        \"COMNT\": \"file_comment\",\n",
    "        \"FFMT\": \"file_format\",\n",
    "        \"FNAME\": \"file_name\",\n",
    "        \"FPATH\": \"file_path\",\n",
    "        \"FMATCH\": \"file_match\"\n",
    "    }\n",
    "\n",
    "class AudStaticData(DataStaticInfo):\n",
    "    EMPTY_VAL = '-'\n",
    "    FNAME_SEP = \"-\"\n",
    "    ANOT_SEP = '\\t'\n",
    "    FS_k = \"fs\"\n",
    "    BEGIN_k = \"begin\"; END_k = \"end\"; LABEL_k = \"label\"\n",
    "    ANOTE_COLS = [BEGIN_k, END_k, LABEL_k]\n",
    "\n",
    "    LUNG_LOCS = [\"LU\", \"RU\", \"LL\", \"RL\"]\n",
    "\n",
    "    LBA_k = \"LBA\"; VBA_k = \"VBA\"; BA_k = \"BA\"\n",
    "    \n",
    "    AUD_TAG = \"aud--\"\n",
    "    ANOT_TAG = \"anot--\"\n",
    "    AUDIO_FPATH_k = f\"audio--file_path\"\n",
    "    ANOT_FPATH_k = f\"anot--file_path\"\n",
    "\n",
    "EXP_VER = \"v9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:12,  1.10s/it]/tmp/ipykernel_439192/2246210998.py:77: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, fs = librosa.load(audio_fp, sr=None, mono=True, offset=offset, duration=dur)\n",
      "/home/jeevan/Jeevan_K/Projects/Pnoi-phone/pnoicorpus-etl/env-pnoi/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "25it [00:25,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "class AudioDataProcess(AudStaticData):\n",
    "\n",
    "\n",
    "    DRY_RUN = False\n",
    "    \n",
    "    PAD_DUR = 0.2\n",
    "    GAP_DUR = 9.0\n",
    "    GAP_k = \"gap\"\n",
    "    DUR_k = \"duration\"\n",
    "    \n",
    "\n",
    "    SIGNAL_k = \"signal\"\n",
    "    LABEL_DF_k = \"label_df\"\n",
    "\n",
    "    AUD_EXPORT_FOLDER = f\"data_export_{EXP_VER}\"\n",
    "    PNOI_SPLIT_AUD_CSV_PATH = f\"pnoiloc_split_aud_{EXP_VER}.csv\"\n",
    "\n",
    "    \n",
    "    PNOI_FILT_DF: pd.DataFrame\n",
    "    PNOI_SPLIT_AUD_DF: pd.DataFrame\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame) -> None:\n",
    "        self.PNOI_FILT_DF = data_df\n",
    "\n",
    "        self.PNOI_SPLIT_AUD_DF = self.process_audio()\n",
    "\n",
    "\n",
    "    def anot_breath_loc_chunks(self, audio_fp: str, anot_fp: str) -> list[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Split audio file into chunks based on duration b/w breaths in the audio file.\n",
    "        The breaths are annotated in the annotation file.\n",
    "        The annotation file is a tsv file exported from audacity.\n",
    "        \"\"\"\n",
    "\n",
    "        anot_df: pd.DataFrame = pd.read_csv(anot_fp, sep=self.ANOT_SEP, names=self.ANOTE_COLS) \n",
    "        # Read annotation labeled with audacity tsv file\n",
    "\n",
    "        anot_df[self.AUDIO_FPATH_k] = audio_fp\n",
    "        anot_df[self.DUR_k] = anot_df[self.END_k] - anot_df[self.BEGIN_k] \n",
    "        # Calculate duration of each label marke in annotation\n",
    "\n",
    "        anot_df[self.GAP_k] = anot_df[self.BEGIN_k].shift(-1) - anot_df[self.END_k] \n",
    "        # Calculate gap between previous label end and next label start: give the gap between labels\n",
    "\n",
    "        gap_filt = (anot_df[self.GAP_k] > self.GAP_DUR) | (anot_df[self.GAP_k].isnull()) \n",
    "        # Filter rows where gap b/w labels is above the threshold (GAP)\n",
    "        anot_gap_df = anot_df.loc[gap_filt] # Apply filter\n",
    "\n",
    "        i_splits = sorted(set([0] + list(anot_gap_df.index + 1))) \n",
    "        # Get row index of those breakpoints (breath location chunks)\n",
    "\n",
    "        breath_chunks = [anot_df.iloc[i_splits[n]:i_splits[n+1]] for n in range(len(i_splits) - 1)] \n",
    "        # Split chunks using the index of breakpoints\n",
    "\n",
    "        # assert len(chunks) == 4 # check if there are 4 chunks\n",
    "\n",
    "        return breath_chunks\n",
    "    \n",
    "    def extract_signal_chunk(self, chunks_DF: pd.DataFrame, is_plot=False):\n",
    "\n",
    "        # Get begin and end values of chunk\n",
    "        t_begin = chunks_DF.iloc[0][self.BEGIN_k]\n",
    "        t_end = chunks_DF.iloc[-1][self.END_k]\n",
    "\n",
    "        # Calculate offset (with Padding)\n",
    "        offset = (t_begin - self.PAD_DUR)\n",
    "        dur = (t_end - t_begin + 2*self.PAD_DUR)\n",
    "\n",
    "        # Offset chunk DF\n",
    "        chunks_DF.loc[:, self.ANOTE_COLS[:-1]] -= offset\n",
    "\n",
    "        # label DF\n",
    "        label_DF = chunks_DF.loc[:, self.ANOTE_COLS]\n",
    "        \n",
    "        # Extract audio signal from audio file\n",
    "        audio_fp = chunks_DF.iloc[0][self.AUDIO_FPATH_k]\n",
    "        signal, fs = librosa.load(audio_fp, sr=None, mono=True, offset=offset, duration=dur)\n",
    "\n",
    "        # Normalize signal\n",
    "        signal = librosa.util.normalize(signal, )\n",
    "\n",
    "        # PLOT signals\n",
    "        if is_plot:\n",
    "            plt.title(os.path.basename(audio_fp))\n",
    "            plt.xlabel(\"t(s)\"); plt.ylabel(\"amp\")\n",
    "            plt.plot(np.linspace(0, dur, len(signal)), signal)\n",
    "            plt.stem(chunks_DF.iloc[:][self.BEGIN_k], np.ones(len(chunks_DF)))\n",
    "            plt.stem(chunks_DF.iloc[:][self.END_k], np.ones(len(chunks_DF)), 'r')\n",
    "            plt.show()\n",
    "\n",
    "        return {\n",
    "            self.FS_k: fs, # sampling frequency\n",
    "            self.AUDIO_FPATH_k: audio_fp, # audio file path\n",
    "            self.SIGNAL_k: signal, # audio signal\n",
    "            self.LABEL_DF_k: label_DF, # label dataframe\n",
    "            }\n",
    "    \n",
    "    def export_audio_signals(self, aud_info: dict, loc_i: int) -> tuple[str]:\n",
    "        fname = os.path.basename(aud_info[self.AUDIO_FPATH_k]) # get filename\n",
    "\n",
    "        '''\n",
    "        [\"app_code 0\", \"sub_id 1\", \"file_class 2\", \"file_ID 3\", \"comment 4\", \"file_format 5\"]'''\n",
    "\n",
    "        fn_parts = fname.split(self.FNAME_SEP) # split filename into parts\n",
    "        n_fclass = fn_parts[2] # get filename class\n",
    "        fn_parts[2] = n_fclass if self.LBA_k in n_fclass else f\"{n_fclass}_{self.LUNG_LOCS[loc_i]}\" # update filename class\n",
    "        n_aud_fname = self.FNAME_SEP.join(fn_parts[:-1]) # join filename parts\n",
    "\n",
    "        #create export folder\n",
    "        export_folder_path = os.path.join(REPORTS, self.AUD_EXPORT_FOLDER); mkdir(export_folder_path)\n",
    "        sub_folder_path = os.path.join(export_folder_path, fn_parts[1]); mkdir(sub_folder_path)\n",
    "\n",
    "        \n",
    "        # export audio file\n",
    "        n_aud_fpath = os.path.join(sub_folder_path, f\"{n_aud_fname}.wav\")\n",
    "        if not self.DRY_RUN: sf.write(n_aud_fpath, aud_info[self.SIGNAL_k], aud_info[self.FS_k]) # export audio file\n",
    "        \n",
    "        # export annotation file\n",
    "        n_anotpath = os.path.join(sub_folder_path, f\"{n_aud_fname}.txt\")\n",
    "        anot_df: pd.DataFrame = aud_info[self.LABEL_DF_k]\n",
    "        if not self.DRY_RUN: anot_df.to_csv(n_anotpath, sep='\\t', index=False, header=False) # export annotation file\n",
    "\n",
    "        return {\n",
    "            f\"{self.AUDIO_FPATH_k}\": n_aud_fpath, \n",
    "            f\"{self.ANOT_FPATH_k}\": n_anotpath,\n",
    "            f\"{self.fkeys['FCLASS']}\": fn_parts[2],\n",
    "            f\"{self.fkeys['SID']}\": fn_parts[1],\n",
    "            }\n",
    "        \n",
    "    def process_audio(self):\n",
    "\n",
    "        BA_str_match = f\"{self.ANOT_TAG}{self.VBA_k}|{self.ANOT_TAG}{self.LBA_k}\"\n",
    "        filt = self.PNOI_FILT_DF.columns.str.contains(BA_str_match)\n",
    "        BA_cols = self.PNOI_FILT_DF.columns[filt]\n",
    "        \n",
    "\n",
    "        for li, loc in enumerate(self.LUNG_LOCS):\n",
    "            BA_cols = [ f\"{li}~{col}\" if loc in f\"{'_'}~{col}\" else col for col in BA_cols]\n",
    "\n",
    "        for li, loc in enumerate([\"before\", \"after\"]):\n",
    "            BA_cols = [ f\"{li}~{col}\" if loc in col else col for col in BA_cols]\n",
    "\n",
    "        for li, loc in enumerate([self.VBA_k, self.LBA_k]):\n",
    "            BA_cols = [ f\"{li}~{col}\" if loc in col else col for col in BA_cols]\n",
    "\n",
    "        # print(sorted(BA_cols))\n",
    "\n",
    "        BA_cols = sorted(BA_cols)\n",
    "\n",
    "        aud_info_dicts = []\n",
    "        for _, sub_info in tqdm(self.PNOI_FILT_DF.iloc[:].iterrows()):\n",
    "\n",
    "            all_breath_chunks = []\n",
    "            for col in BA_cols:\n",
    "\n",
    "                col = col.split('~')[-1]\n",
    "                audio_fp = sub_info[col.replace(self.ANOT_TAG, '')]\n",
    "                anote_fp = sub_info[col]\n",
    "\n",
    "                if anote_fp == self.EMPTY_VAL: continue\n",
    "\n",
    "                ba_chunks = self.anot_breath_loc_chunks(audio_fp, anote_fp)\n",
    "\n",
    "                # all_breath_chunks.extend(ba_chunks)\n",
    "\n",
    "                # print(BA_cols_n)\n",
    "                for ci, chunk in enumerate(ba_chunks):\n",
    "                    chunk_info = self.extract_signal_chunk(chunk, is_plot=False)\n",
    "\n",
    "                    aud_info = self.export_audio_signals(chunk_info, ci)\n",
    "\n",
    "                    aud_info_dicts.append(aud_info)\n",
    "\n",
    "                    # break        \n",
    "            # break\n",
    "\n",
    "        aud_info_df = pd.DataFrame(aud_info_dicts)\n",
    "\n",
    "        aud_info_df.to_csv(f\"{REPORTS}/{self.PNOI_SPLIT_AUD_CSV_PATH}\")\n",
    "\n",
    "        return aud_info_df\n",
    "\n",
    "\n",
    "        \n",
    "pnoidata_audproc = AudioDataProcess(pnoidata_filter.PNOI_FILT_DF)\n",
    "\n",
    "# pnoidata_audproc.process_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fs</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>file_class</th>\n",
       "      <th>audio--file_path</th>\n",
       "      <th>anot--file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16000</td>\n",
       "      <td>shreyamgupta_78aa423a</td>\n",
       "      <td>_before_LU</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16000</td>\n",
       "      <td>shreyamgupta_78aa423a</td>\n",
       "      <td>_before_RU</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16000</td>\n",
       "      <td>shreyamgupta_78aa423a</td>\n",
       "      <td>_before_LL</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16000</td>\n",
       "      <td>shreyamgupta_78aa423a</td>\n",
       "      <td>_before_RL</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/shreyamgupta_78aa423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16000</td>\n",
       "      <td>sannashoukat_5213fe84</td>\n",
       "      <td>_before_LU</td>\n",
       "      <td>reports/pnoi_sync_data_v9/sannashoukat_5213fe8...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/sannashoukat_5213fe8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>16000</td>\n",
       "      <td>sujatan_bdd161b6</td>\n",
       "      <td>_after_RL</td>\n",
       "      <td>reports/pnoi_sync_data_v9/sujatan_bdd161b6/pno...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/sujatan_bdd161b6/pno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>16000</td>\n",
       "      <td>lokeshk_90b4871a</td>\n",
       "      <td>_before_LU</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>16000</td>\n",
       "      <td>lokeshk_90b4871a</td>\n",
       "      <td>_before_RU</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>16000</td>\n",
       "      <td>lokeshk_90b4871a</td>\n",
       "      <td>_before_LL</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>16000</td>\n",
       "      <td>lokeshk_90b4871a</td>\n",
       "      <td>_before_RL</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "      <td>reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fs                 sub_id  file_class  \\\n",
       "0    16000  shreyamgupta_78aa423a  _before_LU   \n",
       "1    16000  shreyamgupta_78aa423a  _before_RU   \n",
       "2    16000  shreyamgupta_78aa423a  _before_LL   \n",
       "3    16000  shreyamgupta_78aa423a  _before_RL   \n",
       "4    16000  sannashoukat_5213fe84  _before_LU   \n",
       "..     ...                    ...         ...   \n",
       "134  16000       sujatan_bdd161b6   _after_RL   \n",
       "135  16000       lokeshk_90b4871a  _before_LU   \n",
       "136  16000       lokeshk_90b4871a  _before_RU   \n",
       "137  16000       lokeshk_90b4871a  _before_LL   \n",
       "138  16000       lokeshk_90b4871a  _before_RL   \n",
       "\n",
       "                                      audio--file_path  \\\n",
       "0    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...   \n",
       "1    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...   \n",
       "2    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...   \n",
       "3    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...   \n",
       "4    reports/pnoi_sync_data_v9/sannashoukat_5213fe8...   \n",
       "..                                                 ...   \n",
       "134  reports/pnoi_sync_data_v9/sujatan_bdd161b6/pno...   \n",
       "135  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...   \n",
       "136  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...   \n",
       "137  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...   \n",
       "138  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...   \n",
       "\n",
       "                                       anot--file_path  \n",
       "0    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...  \n",
       "1    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...  \n",
       "2    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...  \n",
       "3    reports/pnoi_sync_data_v9/shreyamgupta_78aa423...  \n",
       "4    reports/pnoi_sync_data_v9/sannashoukat_5213fe8...  \n",
       "..                                                 ...  \n",
       "134  reports/pnoi_sync_data_v9/sujatan_bdd161b6/pno...  \n",
       "135  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...  \n",
       "136  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...  \n",
       "137  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...  \n",
       "138  reports/pnoi_sync_data_v9/lokeshk_90b4871a/pno...  \n",
       "\n",
       "[139 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PNOILOC_SPLIT_AUD_CSV_PATH = f\"reports/pnoiloc_split_aud_{EXP_VER}.csv\"\n",
    "\n",
    "class SyncBASignals(AudStaticData):\n",
    "\n",
    "    DRY_RUN = True\n",
    "    \n",
    "    FS = 16000\n",
    "    MATCH = \"match\"\n",
    "    EXPORT_FOLDER = f\"pnoi_sync_data_{EXP_VER}\"\n",
    "\n",
    "    PLOT_EXPORT_FOLDER = f\"pnoi_sync_data_plot_{EXP_VER}\"\n",
    "\n",
    "    PNOI_SYNC_AUD_CSV_PATH = f\"{REPORTS}/pnoi_sync_aud_{EXP_VER}.csv\"\n",
    "\n",
    "    PNOI_SPLIT_AUD_DF: pd.DataFrame\n",
    "    PNOI_SYNC_AUD_DF: pd.DataFrame\n",
    "    \n",
    "    def __init__(self, split_aud_csv_path: str) -> None:\n",
    "\n",
    "        self.PNOI_SPLIT_AUD_DF = pd.read_csv(split_aud_csv_path)\n",
    "\n",
    "        # self.PNOI_SYNC_AUD_DF = self.process_ba_signals()\n",
    "\n",
    "    # Plot signal and annotation\n",
    "    def plot_sig(self, aud, anot, fs, scale=1.0, c='blue'):\n",
    "        t = np.linspace(0, len(aud)/fs, len(aud))\n",
    "        plt.stem(anot[self.BEGIN_k], np.ones(len(anot))*1.2, 'r')\n",
    "        plt.stem(anot[self.END_k], np.ones(len(anot))*1.1, 'g')\n",
    "        plt.plot(t, aud*scale, color=c)\n",
    "\n",
    "    def join_ba_signals(self, rv, is_plot=False):\n",
    "\n",
    "        # helper functions\n",
    "        load_audio = lambda fp: librosa.load(fp, sr=self.FS, mono=True)[0] # Load audio signal\n",
    "        pad_sig = lambda sig, max_len: np.pad(sig, (0, max_len - len(sig)), mode='constant') # Pad signal with zeros\n",
    "        read_anot = lambda fp: pd.read_csv(fp, sep=self.ANOT_SEP, names=self.ANOTE_COLS) # Read annotation labeled with audacity tsv file\n",
    "\n",
    "        # Read annotation\n",
    "        vba_anot = read_anot(rv[f\"{self.ANOT_FPATH_k}{self.META_SEP}{self.VBA_k}\"])\n",
    "        lba_anot = read_anot(rv[f\"{self.ANOT_FPATH_k}{self.META_SEP}{self.LBA_k}\"])\n",
    "\n",
    "        # Load audio signal\n",
    "        vba_sig = load_audio(rv[f\"{self.AUDIO_FPATH_k}{self.META_SEP}{self.VBA_k}\"])\n",
    "        lba_sig = load_audio(rv[f\"{self.AUDIO_FPATH_k}{self.META_SEP}{self.LBA_k}\"])\n",
    "\n",
    "        # Pad signals with zeros to make them equal length\n",
    "        max_sig_len = max(len(vba_sig), len(lba_sig)) # get max length of the two signals\n",
    "\n",
    "        vba_sig = pad_sig(vba_sig, max_sig_len)\n",
    "        lba_sig = pad_sig(lba_sig, max_sig_len)\n",
    "\n",
    "        \n",
    "\n",
    "        # Join the two signals\n",
    "        ba_sig = np.array([vba_sig, lba_sig]).T\n",
    "\n",
    "        #create export folder\n",
    "        fname = os.path.basename(rv[f\"{self.AUDIO_FPATH_k}{self.META_SEP}{self.VBA_k}\"]) # get filename\n",
    "        n_filename = os.path.splitext(fname.replace(self.VBA_k, self.BA_k))[0] # remove extension and replace vba with ba\n",
    "        \n",
    "        export_folder_path = os.path.join(REPORTS, self.EXPORT_FOLDER); mkdir(export_folder_path)\n",
    "        sub_folder_path = os.path.join(export_folder_path, rv[self.fkeys['SID']]); mkdir(sub_folder_path)\n",
    "\n",
    "        # Export audio file\n",
    "        audio_filename = os.path.join(sub_folder_path, f\"{n_filename}.wav\")\n",
    "        if not self.DRY_RUN: \n",
    "            sf.write(audio_filename, ba_sig, self.FS) # export audio file\n",
    "\n",
    "        # Export annotation file\n",
    "        anot_filepath = os.path.join(sub_folder_path, f\"{n_filename}.txt\")\n",
    "        if not self.DRY_RUN: \n",
    "            vba_anot.to_csv(anot_filepath, sep=self.ANOT_SEP, index=False, header=False)\n",
    "\n",
    "\n",
    "        # plot signal and annotation\n",
    "        if is_plot: \n",
    "            plt.figure(figsize=(128, 12))\n",
    "            plt.subplots(2, 1)\n",
    "\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.title(f\"{n_filename}\\nVBA\", fontsize=12)\n",
    "            self.plot_sig(vba_sig, vba_anot, self.FS, c=\"cadetblue\")\n",
    "\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.title(\"LBA\", fontsize=12)\n",
    "            self.plot_sig(lba_sig, lba_anot, self.FS, c=\"lightsalmon\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plot_folder_path = os.path.join(REPORTS, self.PLOT_EXPORT_FOLDER); mkdir(plot_folder_path)\n",
    "\n",
    "            plt.savefig(os.path.join(plot_folder_path, f\"{n_filename}.png\"))\n",
    "            # print(plot_folder_path, f\"{n_filename}.png\")\n",
    "            \n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        return {\n",
    "            self.FS_k: self.FS, # sampling frequency\n",
    "            self.fkeys['SID']: rv[self.fkeys['SID']], # subject ID\n",
    "            self.fkeys['FCLASS']: rv[self.MATCH], # file class\n",
    "            self.AUDIO_FPATH_k: audio_filename, # audio file path\n",
    "            self.ANOT_FPATH_k: anot_filepath, # label dataframe\n",
    "            }\n",
    "    \n",
    "\n",
    "    def process_ba_signals(self):\n",
    "        subjects = self.PNOI_SPLIT_AUD_DF[self.fkeys['SID']].unique()\n",
    "\n",
    "        ba_sync_aud_dicts = []\n",
    "        for subject in tqdm(subjects[:]): # SUBJECT LOOP\n",
    "            filt = self.PNOI_SPLIT_AUD_DF[self.fkeys['SID']] == subject\n",
    "            sub_df = self.PNOI_SPLIT_AUD_DF[filt]\n",
    "\n",
    "            ba_match_str = f\"{self.VBA_k}|{self.LBA_k}\"\n",
    "\n",
    "            match_df = sub_df.loc[:, (self.fkeys['FCLASS'],)].replace(ba_match_str, '', regex=True)\n",
    "            sub_df.loc[:, (self.MATCH, )] = match_df.loc[:, self.fkeys['FCLASS']]\n",
    "\n",
    "            filt = sub_df[self.fkeys['FCLASS']].str.contains(self.VBA_k)\n",
    "            sub_VBA = sub_df.loc[filt]\n",
    "            sub_LBA = sub_df.loc[~filt]\n",
    "\n",
    "            merge_cols = [self.MATCH, self.fkeys['SID']]\n",
    "            merge_sufix = (f\"_{self.VBA_k}\", f\"_{self.LBA_k}\")\n",
    "            sub_df2 = sub_VBA.merge(sub_LBA, how=\"inner\", on=merge_cols, suffixes=merge_sufix)\n",
    "\n",
    "            for _, rv in sub_df2.iterrows():\n",
    "                ba_sync_aud_dicts += [self.join_ba_signals(rv, is_plot=False)]\n",
    "\n",
    "\n",
    "\n",
    "        aud_info_df = pd.DataFrame(ba_sync_aud_dicts)\n",
    "\n",
    "        aud_info_df.to_csv(f\"{self.PNOI_SYNC_AUD_CSV_PATH}\")\n",
    "\n",
    "        return aud_info_df\n",
    "\n",
    "pnoidata_audsync = SyncBASignals(PNOILOC_SPLIT_AUD_CSV_PATH)\n",
    "pnoidata_audsync.process_ba_signals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
